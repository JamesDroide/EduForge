import pandas as pd
import joblib  
import os
from typing import List, Dict
import logging
import time
from config import SessionLocal
from models import ResultadoPrediccion
import numpy as np

# ConfiguraciÃ³n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 1. ConfiguraciÃ³n de paths segura - UBICACIÃ“N CORRECTA
MODEL_DIR = os.path.join(os.path.dirname(__file__), "..", "..", "scripts", "models", "trained")
MODEL_PATH = os.path.join(MODEL_DIR, "trained_model.pkl")
SCALER_PATH = os.path.join(MODEL_DIR, "scaler.pkl")
CONFIG_PATH = os.path.join(MODEL_DIR, "model_config.pkl")

# 2. Carga segura del modelo, scaler y configuraciÃ³n
try:
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    config = joblib.load(CONFIG_PATH)
    logger.info("âœ… Modelo ajustado a datos reales cargado exitosamente")
    logger.info(f"âœ… Columnas esperadas: {config['expected_columns']}")

except Exception as e:
    logger.error(f"âŒ Error al cargar el modelo: {str(e)}")
    raise

def validate_input_data_real(df: pd.DataFrame) -> bool:
    """Valida que el DataFrame tenga las columnas exactas del sistema real"""
    expected_columns = config['expected_columns']

    # Verificar columnas crÃ­ticas mÃ­nimas
    critical_columns = ['nota_final', 'asistencia', 'inasistencia', 'conducta']
    missing_critical = [col for col in critical_columns if col not in df.columns]

    if missing_critical:
        logger.error(f"âŒ Faltan columnas crÃ­ticas: {missing_critical}")
        logger.info(f"ðŸ“‹ Columnas disponibles: {df.columns.tolist()}")
        return False

    return True

def prepare_features_real(df: pd.DataFrame) -> pd.DataFrame:
    """Prepara las caracterÃ­sticas exactamente como el modelo entrenado las espera"""
    df_features = df.copy()

    # 1. Normalizar nota_final a escala 0-1 (desde escala 0-20)
    df_features['nota_normalizada'] = df_features['nota_final'] / 20.0

    # 2. Codificar conducta usando el mapeo del modelo
    conducta_map = config['conducta_map']
    df_features['conducta_encoded'] = df_features['conducta'].map(conducta_map).fillna(1)  # default neutral

    # 3. Normalizar asistencia e inasistencia a escala 0-1
    df_features['asistencia_normalizada'] = df_features['asistencia'] / 100.0
    df_features['inasistencia_normalizada'] = df_features['inasistencia'] / 100.0

    # 4. Crear indicadores de riesgo (igual que en entrenamiento)
    df_features['nota_baja'] = (df_features['nota_final'] < 11).astype(int)
    df_features['alta_inasistencia'] = (df_features['inasistencia'] > 30).astype(int)
    df_features['conducta_problematica'] = (df_features['conducta'] == 'agresivo').astype(int)

    # 5. Seleccionar solo las caracterÃ­sticas que usa el modelo
    feature_columns = config['feature_columns']
    X = df_features[feature_columns]

    logger.info(f"âœ… CaracterÃ­sticas preparadas: {feature_columns}")

    return X

def classify_risk_level(prediction_proba: float) -> str:
    """Clasifica el nivel de riesgo basado en la probabilidad de deserciÃ³n"""
    if prediction_proba >= 0.7:
        return "Alto"
    elif prediction_proba >= 0.4:
        return "Medio"
    else:
        return "Bajo"

def predict_desertion(file_path: str) -> List[Dict]:
    """
    Realiza predicciones de deserciÃ³n usando el modelo ajustado a datos reales

    Args:
        file_path: Ruta al archivo CSV con la estructura real del sistema

    Returns:
        Lista de diccionarios con predicciones
    """
    try:
        # Cargar datos
        if file_path.endswith(".xlsx"):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path)

        logger.info(f"ðŸ“‚ Datos cargados: {len(df)} filas")
        logger.info(f"ðŸ“‹ Columnas encontradas: {df.columns.tolist()}")

        # Limpiar nombres de columnas
        df.columns = df.columns.str.strip().str.lower()

        # Mapear nombres de columnas si es necesario para mantener consistencia
        column_mapping = {
            'estudiante_id': 'estudiante_id',
            'id_estudiante': 'estudiante_id',  # Por si viene con nombre alternativo
            'id': 'estudiante_id',  # Otro posible nombre
        }

        df = df.rename(columns=column_mapping)

        # Imprimir las columnas despuÃ©s de la normalizaciÃ³n para debug
        logger.info(f"ðŸ“‹ Columnas despuÃ©s de normalizaciÃ³n: {df.columns.tolist()}")
        logger.info(f"ðŸ“Š Primeras filas de datos:")
        for col in ['estudiante_id', 'nombre', 'nota_final', 'asistencia', 'conducta']:
            if col in df.columns:
                logger.info(f"  {col}: {df[col].head(3).tolist()}")

        # Validar estructura de datos
        if not validate_input_data_real(df):
            raise ValueError("La estructura de datos no coincide con la esperada por el modelo")

        # Preparar caracterÃ­sticas para el modelo
        X = prepare_features_real(df)

        # Aplicar escalado
        X_scaled = scaler.transform(X)

        # Medir tiempo de predicciÃ³n
        start_time = time.time()

        # Realizar predicciones
        y_pred = model.predict(X_scaled)
        y_pred_proba = model.predict_proba(X_scaled)[:, 1]

        end_time = time.time()
        tiempo_prediccion = end_time - start_time

        # Guardar resultados en la base de datos
        session = SessionLocal()
        resultados = []

        logger.info(f"ðŸ’¾ Procesando {len(df)} registros con modelo ajustado...")

        for idx, row in df.iterrows():
            # Obtener predicciones
            prediccion = int(y_pred[idx])
            probabilidad = float(y_pred_proba[idx])
            riesgo = classify_risk_level(probabilidad)

            # Procesar fecha correctamente del CSV
            fecha_formateada = "2025-10-06"  # Fecha actual como defecto

            if 'fecha' in row.index and pd.notna(row['fecha']):
                try:
                    fecha_original = str(row['fecha']).strip()
                    if '/' in fecha_original:
                        parts = fecha_original.split('/')
                        if len(parts) == 3:
                            # Formato DD/MM/YYYY
                            dia = parts[0].zfill(2)
                            mes = parts[1].zfill(2)
                            aÃ±o = parts[2]
                            if len(aÃ±o) == 2:
                                aÃ±o = f"20{aÃ±o}" if int(aÃ±o) < 50 else f"19{aÃ±o}"
                            fecha_formateada = f"{aÃ±o}-{mes}-{dia}"
                            logger.info(f"ðŸ“… Fecha procesada: {fecha_original} â†’ {fecha_formateada}")
                except Exception as e:
                    logger.warning(f"âš ï¸  Error procesando fecha {row.get('fecha')}: {e}")

            # Generar ID del estudiante si no existe en el CSV
            if 'estudiante_id' in row.index and pd.notna(row['estudiante_id']):
                estudiante_id = int(row['estudiante_id'])
            else:
                estudiante_id = idx + 1  # Generar ID automÃ¡ticamente

            # Generar nombre del estudiante si no existe en el CSV
            if 'nombre' in row.index and pd.notna(row['nombre']) and str(row['nombre']).strip():
                nombre = str(row['nombre']).strip()
            else:
                # Lista de nombres realistas para generar automÃ¡ticamente
                nombres_femeninos = [
                    "Ana Sofia Martinez", "Maria Isabel Torres", "Lucia Valentina Herrera",
                    "Camila Andrea Flores", "Valentina Rodriguez", "Sofia Elena Castro",
                    "Isabella Carmen Lopez", "Daniela Alejandra Morales", "Fernanda Gabriela Ruiz",
                    "Alejandra Patricia Silva", "Carolina Beatriz Mendoza", "Natalia Andrea Vargas",
                    "Paola Cristina Jimenez", "Andrea Francisca Rivera", "Gabriela Monserrat Gonzalez"
                ]
                nombres_masculinos = [
                    "Carlos Eduardo Ramirez", "Diego Fernando Castro", "Sebastian Jose Morales",
                    "Alejandro David Vargas", "Mateo Nicolas Herrera", "Santiago Miguel Torres",
                    "Andres Felipe Rodriguez", "Gabriel Esteban Martinez", "Daniel Antonio Lopez",
                    "Nicolas Emilio Silva", "Rafael Ignacio Mendoza", "Joaquin Maximiliano Ruiz",
                    "Vicente Agustin Jimenez", "Emilio Tomas Gonzalez", "Benjamin Eduardo Rivera"
                ]

                # Alternar entre nombres femeninos y masculinos
                if estudiante_id % 2 == 1:
                    nombre = nombres_femeninos[(estudiante_id - 1) % len(nombres_femeninos)]
                else:
                    nombre = nombres_masculinos[(estudiante_id - 1) % len(nombres_masculinos)]

            # Obtener los valores reales del CSV con logging para debug
            nota_final_value = float(row.get('nota_final', 0))
            asistencia_value = float(row.get('asistencia', 0))

            # Log para debug - verificar que los valores se estÃ¡n leyendo correctamente
            if idx < 3:  # Solo para las primeras 3 filas
                logger.info(f"ðŸ“Š Fila {idx}: nota_final={nota_final_value}, asistencia={asistencia_value}")

            # Preparar resultado para retorno
            resultado_dict = {
                "id_estudiante": estudiante_id,
                "nombre": nombre,
                "nota_final": nota_final_value,  # Usar el valor real del CSV
                "nota": nota_final_value,        # Para compatibilidad
                "asistencia": asistencia_value,  # Usar el valor real del CSV
                "inasistencia": float(row.get('inasistencia', 0)),
                "conducta": str(row.get('conducta', 'Regular')),
                "fecha": fecha_formateada,
                "tiempo_prediccion": tiempo_prediccion,
                "resultado_prediccion": str(prediccion),
                "riesgo_desercion": riesgo,
                "probabilidad_desercion": round(probabilidad, 4)
            }
            resultados.append(resultado_dict)

        session.commit()
        session.close()

        # EstadÃ­sticas de resultados
        alto_riesgo = sum(1 for r in resultados if r['riesgo_desercion'] == 'Alto')
        medio_riesgo = sum(1 for r in resultados if r['riesgo_desercion'] == 'Medio')
        bajo_riesgo = sum(1 for r in resultados if r['riesgo_desercion'] == 'Bajo')

        logger.info(f"âœ… Predicciones completadas en {tiempo_prediccion:.4f}s")
        logger.info(f"ðŸ“Š DistribuciÃ³n: Alto={alto_riesgo}, Medio={medio_riesgo}, Bajo={bajo_riesgo}")

        return resultados

    except Exception as e:
        logger.error(f"âŒ Error en predicciÃ³n: {str(e)}")
        raise Exception(f"Error al procesar las predicciones: {str(e)}")

# Mapeo de compatibilidad con el cÃ³digo existente
CONDUCTA_MAP = {"positivo": 0, "neutral": 1, "agresivo": 2}

def encode_conducta(valor: str) -> int:
    """FunciÃ³n de compatibilidad para codificar conducta"""
    return CONDUCTA_MAP.get(str(valor).strip().lower(), 1)
