# üîç Revisi√≥n Integral del C√≥digo - EduForge

## Resumen Ejecutivo

Este documento presenta una revisi√≥n exhaustiva del c√≥digo del sistema EduForge, un sistema de predicci√≥n de deserci√≥n estudiantil desarrollado con FastAPI (backend) y React (frontend).

**Fecha de Revisi√≥n:** 14 de Octubre, 2025  
**Revisado por:** GitHub Copilot Agent  
**Versi√≥n del C√≥digo:** Commit bd6070f

---

## üìä Calificaci√≥n General

| Categor√≠a | Calificaci√≥n | Estado |
|-----------|--------------|--------|
| Seguridad | ‚ö†Ô∏è 6/10 | Requiere Atenci√≥n |
| Calidad de C√≥digo | ‚ö†Ô∏è 7/10 | Mejorable |
| Arquitectura | ‚úÖ 7.5/10 | Buena |
| Rendimiento | ‚ö†Ô∏è 6.5/10 | Requiere Optimizaci√≥n |
| Mantenibilidad | ‚úÖ 7/10 | Aceptable |
| Testing | ‚ùå 3/10 | Cr√≠tico |

---

## üî¥ PROBLEMAS CR√çTICOS

### 1. Credenciales Hardcodeadas en el C√≥digo

**Archivo:** `src/config.py` (l√≠nea 8)  
**Severidad:** üî¥ CR√çTICA

```python
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:jamesdroide@localhost:5432/eduforge")
```

**Problema:**
- La contrase√±a de la base de datos (`jamesdroide`) est√° expuesta en el c√≥digo fuente
- Cualquier persona con acceso al repositorio puede ver las credenciales
- Riesgo de seguridad si el repositorio es p√∫blico o si las credenciales son compartidas

**Recomendaci√≥n:**
```python
# ‚úÖ CORRECTO
DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise ValueError("DATABASE_URL environment variable must be set")

# O usar un valor por defecto gen√©rico sin credenciales reales
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://user:pass@localhost:5432/eduforge")
```

**Adicional:** `notebooks/data_1/data_preprocessing.py` (l√≠nea 5)
```python
ruta_csv = r'C:\Users\james\OneDrive\Documentos\PREGRADO UPAO\...'
```
- Ruta absoluta personal expuesta que revela informaci√≥n del sistema de desarrollo

---

### 2. Ausencia de Tests Automatizados

**Archivo:** `tests/test_api.py`  
**Severidad:** üî¥ CR√çTICA

**Problema:**
- El archivo de tests est√° completamente vac√≠o
- No hay validaci√≥n automatizada del c√≥digo
- Alto riesgo de introducir bugs en producci√≥n
- Dificulta refactorizaci√≥n segura

**Recomendaci√≥n:**
Implementar tests para los componentes cr√≠ticos:

```python
# tests/test_predictor.py
import pytest
from src.models.predictor import predict_desertion, validate_input_data_real
import pandas as pd

def test_predict_desertion_with_valid_data():
    # Crear CSV de prueba
    test_data = pd.DataFrame({
        'estudiante_id': [1, 2],
        'nombre': ['Test 1', 'Test 2'],
        'nota_final': [15.0, 8.0],
        'asistencia': [90.0, 60.0],
        'inasistencia': [10.0, 40.0],
        'conducta': ['positivo', 'neutral']
    })
    test_file = '/tmp/test_data.csv'
    test_data.to_csv(test_file, index=False)
    
    results = predict_desertion(test_file)
    assert len(results) == 2
    assert 'riesgo_desercion' in results[0]

def test_validate_input_data_missing_columns():
    df = pd.DataFrame({'col1': [1, 2]})
    assert validate_input_data_real(df) == False
```

---

### 3. Falta de Validaci√≥n en Endpoints de API

**Archivos:** `src/main.py` (m√∫ltiples endpoints)  
**Severidad:** üî¥ ALTA

**Problema en `/predict`:**
```python
@app.post("/predict")
async def predict(filename: str):
    # No hay validaci√≥n del tipo de archivo
    # No hay sanitizaci√≥n del nombre de archivo
    # Riesgo de path traversal
```

**Vulnerabilidades:**
1. **Path Traversal:** Un atacante podr√≠a usar `filename="../../../etc/passwd"`
2. **Sin validaci√≥n de extensi√≥n:** Podr√≠a intentar ejecutar archivos no CSV
3. **Sin l√≠mite de tama√±o de archivo**

**Recomendaci√≥n:**
```python
import re
from pathlib import Path

@app.post("/predict")
async def predict(filename: str):
    # Validar nombre de archivo
    if not re.match(r'^[\w\-. ]+\.csv$', filename):
        raise HTTPException(status_code=400, detail="Nombre de archivo inv√°lido")
    
    # Prevenir path traversal
    filename = Path(filename).name  # Solo nombre, sin path
    
    # Validar que el archivo existe y es un archivo regular
    file_path = Path(upload_dir) / filename
    if not file_path.is_file():
        raise HTTPException(status_code=404, detail="Archivo no encontrado")
    
    # Continuar con la l√≥gica...
```

---

## ‚ö†Ô∏è PROBLEMAS DE SEVERIDAD ALTA

### 4. Gesti√≥n Inadecuada de Sesiones de Base de Datos

**Archivos:** `src/main.py`, `src/services/risk_service.py`  
**Severidad:** ‚ö†Ô∏è ALTA

**Problemas encontrados:**

**Ejemplo 1: Inconsistencia en cierre de sesiones**
```python
# src/main.py l√≠nea 177
promedio_notas = sum(r.nota for r in resultados) / total_estudiantes
```
- Usa `r.nota` pero el campo correcto es `r.nota_final`
- Esto causar√° errores en tiempo de ejecuci√≥n

**Ejemplo 2: Falta de manejo de excepciones en transacciones**
```python
# src/models/predictor.py l√≠nea 151-157
try:
    session.query(ResultadoPrediccion).delete()
    session.commit()
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Error limpiando registros anteriores: {e}")
    session.rollback()
```
- Bien manejado aqu√≠ ‚úÖ

Pero en otros lugares:
```python
# src/main.py l√≠nea 126-132
session = SessionLocal()
resultados = session.query(ResultadoPrediccion).all()
session.close()
```
- No hay manejo de excepciones
- Si falla la query, la sesi√≥n no se cierra

**Recomendaci√≥n - Usar Context Managers:**
```python
from contextlib import contextmanager

@contextmanager
def get_db_session():
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()

# Uso:
with get_db_session() as session:
    resultados = session.query(ResultadoPrediccion).all()
```

---

### 5. Variables Globales Compartidas (Thread-Safety Issues)

**Archivo:** `src/services/risk_service.py` (l√≠neas 7-8)  
**Severidad:** ‚ö†Ô∏è ALTA

```python
# Variable global para almacenar los √∫ltimos resultados
latest_predictions = []
```

**Problema:**
- En un entorno multi-threaded (uvicorn con m√∫ltiples workers), esta variable global puede causar:
  - Race conditions
  - Data corruption
  - Resultados inconsistentes entre requests

**Recomendaci√≥n:**
```python
# Opci√≥n 1: Usar cach√© distribuido
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend

# Opci√≥n 2: Siempre leer de la base de datos (m√°s confiable)
def get_latest_predictions():
    session = SessionLocal()
    try:
        results = session.query(ResultadoPrediccion).all()
        return [format_prediction(r) for r in results]
    finally:
        session.close()

# Opci√≥n 3: Usar threading.local para datos por thread
import threading
thread_local = threading.local()
```

---

### 6. Inconsistencia en Nombres de Campos de Base de Datos

**Archivos:** M√∫ltiples  
**Severidad:** ‚ö†Ô∏è ALTA

**Problema:**
```python
# src/main.py l√≠nea 177
promedio_notas = sum(r.nota for r in resultados) / total_estudiantes

# Pero en la base de datos el campo es 'nota_final'
# src/models/predictor.py l√≠nea 232
nota_final=nota_final_value,
```

**Evidencia adicional:**
```python
# src/main.py l√≠nea 138
"nota": r.nota_final,  # Mantener 'nota' por compatibilidad
"nota_final": r.nota_final,
```

**Recomendaci√≥n:**
1. Unificar nomenclatura en la base de datos
2. Usar un solo nombre de campo
3. Crear property en el modelo SQLAlchemy si se necesita compatibilidad:

```python
class ResultadoPrediccion(Base):
    __tablename__ = 'resultados_prediccion'
    
    nota_final = Column(Float)
    
    @property
    def nota(self):
        """Alias para compatibilidad"""
        return self.nota_final
```

---

## ‚ö†Ô∏è PROBLEMAS DE SEVERIDAD MEDIA

### 7. Logging Excesivo en Producci√≥n

**Archivo:** `src/services/risk_service.py`  
**Severidad:** ‚ö†Ô∏è MEDIA

**Problema:**
```python
print(f"üîç DEBUG: get_students_at_risk - {len(results)} registros encontrados en BD")
print(f"üîç DEBUG: Procesando estudiante {result.nombre}: nota={nota_value}...")
```

- Uso de `print()` en lugar de logging
- Mensajes DEBUG en c√≥digo de producci√≥n
- Emojis pueden causar problemas de encoding
- Impacto en rendimiento con grandes vol√∫menes de datos

**Recomendaci√≥n:**
```python
import logging

logger = logging.getLogger(__name__)

# Configuraci√≥n en main.py o config.py
logging.basicConfig(
    level=logging.INFO if os.getenv('ENV') == 'production' else logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# En el c√≥digo:
logger.debug(f"Procesando estudiante {result.nombre}: nota={nota_value}")
logger.info(f"Estudiantes procesados: {len(results)}")
```

---

### 8. CORS Demasiado Permisivo

**Archivo:** `src/main.py` (l√≠neas 28-41)  
**Severidad:** ‚ö†Ô∏è MEDIA

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://*.vercel.app",  # ‚ö†Ô∏è Demasiado permisivo
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],  # ‚ö†Ô∏è Permite todos los headers
)
```

**Problemas:**
- Wildcard en subdominios permite potenciales ataques
- `allow_headers=["*"]` es innecesariamente permisivo
- En producci√≥n, deber√≠as especificar or√≠genes exactos

**Recomendaci√≥n:**
```python
# Cargar or√≠genes desde variable de entorno
ALLOWED_ORIGINS = os.getenv(
    'ALLOWED_ORIGINS',
    'http://localhost:3000'
).split(',')

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["Content-Type", "Authorization"],
)
```

---

### 9. Feature Engineering Duplicado

**Archivo:** `src/models/entrenar_modelo_mejorado.py` (l√≠neas 86-118)  
**Severidad:** ‚ö†Ô∏è MEDIA

**Problema:**
- La funci√≥n `feature_engineering_avanzado` tiene l√≥gica compleja
- Esta l√≥gica NO se aplica en `predictor.py` durante la inferencia
- **Inconsistencia entre entrenamiento y predicci√≥n**

**Comparaci√≥n:**

**Entrenamiento (entrenar_modelo_mejorado.py):**
```python
def feature_engineering_avanzado(df):
    # Progreso entre per√≠odos
    df['progreso_notas'] = df['nota_periodo_2'] - df['nota_periodo_1']
    df['tendencia_negativa'] = (df['progreso_notas'] < -0.1).astype(int)
    # ... m√°s features
```

**Predicci√≥n (predictor.py):**
```python
def prepare_features_real(df: pd.DataFrame) -> pd.DataFrame:
    # Solo features b√°sicas, NO incluye progreso_notas
    df_features['nota_normalizada'] = df_features['nota_final'] / 20.0
    df_features['conducta_encoded'] = ...
    # Falta feature_engineering_avanzado
```

**Impacto:**
- El modelo espera caracter√≠sticas que no se proporcionan
- Resultados de predicci√≥n pueden ser incorrectos o inconsistentes
- Error potencial si el modelo busca columnas que no existen

**Recomendaci√≥n:**
1. Extraer feature engineering a un m√≥dulo compartido
2. Aplicar las mismas transformaciones en entrenamiento y predicci√≥n
3. Validar que las caracter√≠sticas coinciden

```python
# src/utils/feature_engineering.py
def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """Crea caracter√≠sticas avanzadas para entrenamiento Y predicci√≥n"""
    df_copy = df.copy()
    
    # 1. Progreso entre per√≠odos (si existen las columnas)
    if 'nota_periodo_1' in df_copy.columns and 'nota_periodo_2' in df_copy.columns:
        df_copy['progreso_notas'] = df_copy['nota_periodo_2'] - df_copy['nota_periodo_1']
    else:
        df_copy['progreso_notas'] = 0  # Valor por defecto
    
    # ... m√°s features
    return df_copy

# Usar en ambos archivos:
# - entrenar_modelo_mejorado.py
# - predictor.py
```

---

### 10. Generaci√≥n de Nombres Falsos en Datos de Producci√≥n

**Archivo:** `src/models/predictor.py` (l√≠neas 195-215)  
**Severidad:** ‚ö†Ô∏è MEDIA

```python
if 'nombre' in row.index and pd.notna(row['nombre']) and str(row['nombre']).strip():
    nombre = str(row['nombre']).strip()
else:
    # Lista de nombres realistas para generar autom√°ticamente
    nombres_femeninos = ["Ana Sofia Martinez", "Maria Isabel Torres", ...]
    # Alternar entre nombres femeninos y masculinos
    if estudiante_id % 2 == 1:
        nombre = nombres_femeninos[(estudiante_id - 1) % len(nombres_femeninos)]
```

**Problemas:**
1. **Privacidad:** Genera nombres que parecen reales pero son falsos
2. **Confusi√≥n:** Los usuarios pueden pensar que son estudiantes reales
3. **Auditor√≠a:** Dificulta rastrear qu√© datos son reales vs generados
4. **GDPR/Compliance:** Problemas potenciales con regulaciones de datos

**Recomendaci√≥n:**
```python
if 'nombre' in row.index and pd.notna(row['nombre']) and str(row['nombre']).strip():
    nombre = str(row['nombre']).strip()
else:
    # Usar un formato que indique claramente que es un placeholder
    nombre = f"Estudiante_{estudiante_id:04d}"
    logger.warning(f"Nombre no proporcionado para ID {estudiante_id}, usando placeholder")
```

---

### 11. Manejo de Fechas Inconsistente

**Archivos:** `src/upload.py`, `src/models/predictor.py`  
**Severidad:** ‚ö†Ô∏è MEDIA

**Problema 1 - Fecha Hardcodeada:**
```python
# src/models/predictor.py l√≠nea 167
fecha_formateada = "2025-10-06"  # Fecha actual como defecto
```
- Fecha hardcodeada en lugar de usar `datetime.now()`

**Problema 2 - L√≥gica de Conversi√≥n Duplicada:**
```python
# src/upload.py l√≠nea 12-34
def excel_date_to_str(excel_date):
    # Conversi√≥n compleja de fechas Excel

# src/models/predictor.py l√≠nea 168-183
if 'fecha' in row.index and pd.notna(row['fecha']):
    try:
        fecha_original = str(row['fecha']).strip()
        if '/' in fecha_original:
            parts = fecha_original.split('/')
            # ... l√≥gica de conversi√≥n duplicada
```

**Recomendaci√≥n:**
```python
# src/utils/date_utils.py
from datetime import datetime
from typing import Union

def normalize_date(date_value: Union[str, int, float]) -> str:
    """Normaliza fechas en diferentes formatos a YYYY-MM-DD"""
    try:
        # Si es string
        if isinstance(date_value, str):
            date_value = date_value.strip()
            
            # Formato DD/MM/YYYY
            if '/' in date_value:
                dt = datetime.strptime(date_value, '%d/%m/%Y')
                return dt.strftime('%Y-%m-%d')
            
            # Formato YYYY-MM-DD (ya normalizado)
            datetime.strptime(date_value, '%Y-%m-%d')
            return date_value
        
        # Si es n√∫mero (Excel serial date)
        if isinstance(date_value, (int, float)):
            base_date = datetime(1899, 12, 30)
            dt = base_date + timedelta(days=float(date_value))
            return dt.strftime('%Y-%m-%d')
    
    except Exception as e:
        logger.warning(f"Error parsing date {date_value}: {e}")
        return datetime.now().strftime('%Y-%m-%d')  # Usar fecha actual
    
    # Default
    return datetime.now().strftime('%Y-%m-%d')
```

---

## üí° MEJORAS DE C√ìDIGO RECOMENDADAS

### 12. Refactorizar Endpoint Monol√≠tico `/predict`

**Archivo:** `src/main.py` (l√≠neas 66-112)  
**Severidad:** üí° MEJORA

**Problema:**
- Endpoint con m√°s de 45 l√≠neas
- M√∫ltiples responsabilidades:
  - Validaci√≥n de archivo
  - Lectura de datos
  - Predicci√≥n
  - Actualizaci√≥n de servicios
- Dificulta testing y mantenimiento

**Recomendaci√≥n:**
```python
# src/services/prediction_service.py
class PredictionService:
    def __init__(self, upload_dir: str):
        self.upload_dir = upload_dir
    
    def validate_file_exists(self, filename: str) -> str:
        """Valida que el archivo existe y retorna la ruta"""
        file_path = os.path.join(self.upload_dir, filename)
        if not os.path.exists(file_path):
            available_files = os.listdir(self.upload_dir)
            raise HTTPException(
                status_code=404,
                detail=f"Archivo no encontrado. Disponibles: {available_files}"
            )
        return file_path
    
    def validate_csv_readable(self, file_path: str) -> pd.DataFrame:
        """Valida que el CSV es legible"""
        try:
            df = pd.read_csv(file_path)
            logger.info(f"CSV v√°lido: {len(df)} filas, columnas: {df.columns.tolist()}")
            return df
        except Exception as e:
            raise HTTPException(
                status_code=400,
                detail=f"Error leyendo CSV: {str(e)}"
            )
    
    async def process_predictions(self, file_path: str) -> List[Dict]:
        """Procesa predicciones y actualiza servicios"""
        # Validar CSV
        self.validate_csv_readable(file_path)
        
        # Predicciones
        predictions = predict_desertion(file_path)
        
        # Actualizar servicios
        update_latest_predictions(predictions)
        update_attendance_data(predictions)
        
        return predictions

# En main.py
prediction_service = PredictionService(UPLOAD_DIR)

@app.post("/predict")
async def predict(filename: str):
    try:
        return await prediction_service.process_predictions(
            prediction_service.validate_file_exists(filename)
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error en predicci√≥n: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

### 13. Eliminar C√≥digo Comentado y Debug

**M√∫ltiples Archivos**  
**Severidad:** üí° MEJORA

**Problemas encontrados:**
```python
# src/main.py l√≠nea 72
print(f"Buscando archivo en: {file_path}")  # Para depuraci√≥n

# src/services/risk_service.py l√≠neas 24, 39, 40
print(f"üîç DEBUG: get_students_at_risk...")
print(f"üîç DEBUG: Procesando estudiante...")
```

**Recomendaci√≥n:**
- Usar logging apropiado en lugar de print()
- Configurar niveles de log (DEBUG, INFO, WARNING, ERROR)
- Remover mensajes DEBUG del c√≥digo de producci√≥n

---

### 14. Optimizar Queries de Base de Datos

**Archivo:** `src/services/risk_service.py`  
**Severidad:** üí° MEJORA

**Problema:**
```python
def get_students_at_risk(self):
    results = db.query(ResultadoPrediccion).all()  # Trae TODOS los registros
    
    all_students = []
    for result in results:
        # Procesa cada uno individualmente
        all_students.append({...})
```

**Problemas de rendimiento:**
- Trae todos los registros sin paginaci√≥n
- Procesa datos en Python que podr√≠an procesarse en SQL
- Sin √≠ndices en columnas frecuentemente consultadas

**Recomendaci√≥n:**
```python
# Agregar √≠ndices en el modelo
class ResultadoPrediccion(Base):
    __tablename__ = 'resultados_prediccion'
    
    id = Column(Integer, primary_key=True, index=True)
    id_estudiante = Column(Integer, index=True)  # ‚úÖ √çndice
    riesgo_desercion = Column(String, index=True)  # ‚úÖ √çndice para filtros
    fecha = Column(DateTime, index=True)  # ‚úÖ √çndice para ordenamiento

# Usar paginaci√≥n
def get_students_at_risk(self, page: int = 1, page_size: int = 50):
    offset = (page - 1) * page_size
    
    results = db.query(ResultadoPrediccion)\
        .filter(ResultadoPrediccion.riesgo_desercion == 'Alto')\
        .order_by(ResultadoPrediccion.probabilidad_desercion.desc())\
        .limit(page_size)\
        .offset(offset)\
        .all()
    
    total = db.query(ResultadoPrediccion)\
        .filter(ResultadoPrediccion.riesgo_desercion == 'Alto')\
        .count()
    
    return {
        'students': [format_student(r) for r in results],
        'page': page,
        'page_size': page_size,
        'total': total,
        'total_pages': (total + page_size - 1) // page_size
    }
```

---

### 15. Validaci√≥n de Datos de Entrada

**Archivo:** `src/models/predictor.py`  
**Severidad:** üí° MEJORA

**Problema:**
```python
# No hay validaci√≥n de rangos
nota_final_value = float(row.get('nota_final', 0))
asistencia_value = float(row.get('asistencia', 0))
```

**Riesgos:**
- Valores negativos
- Valores fuera de rango (ej: asistencia > 100%)
- Valores None o NaN sin manejo

**Recomendaci√≥n:**
```python
def validate_and_sanitize_row(row: pd.Series) -> Dict:
    """Valida y sanitiza los datos de una fila"""
    
    # Nota final: debe estar entre 0 y 20
    nota_final = float(row.get('nota_final', 0))
    if nota_final < 0 or nota_final > 20:
        logger.warning(f"Nota fuera de rango: {nota_final}, ajustando")
        nota_final = max(0, min(20, nota_final))
    
    # Asistencia: debe estar entre 0 y 100
    asistencia = float(row.get('asistencia', 0))
    if asistencia < 0 or asistencia > 100:
        logger.warning(f"Asistencia fuera de rango: {asistencia}, ajustando")
        asistencia = max(0, min(100, asistencia))
    
    # Conducta: debe ser uno de los valores v√°lidos
    conducta = str(row.get('conducta', 'neutral')).lower()
    valid_conductas = ['positivo', 'neutral', 'agresivo']
    if conducta not in valid_conductas:
        logger.warning(f"Conducta inv√°lida: {conducta}, usando 'neutral'")
        conducta = 'neutral'
    
    return {
        'nota_final': nota_final,
        'asistencia': asistencia,
        'conducta': conducta,
        'inasistencia': float(row.get('inasistencia', 100 - asistencia))
    }
```

---

## üèóÔ∏è ARQUITECTURA Y DISE√ëO

### 16. Falta de Separaci√≥n de Configuraci√≥n por Entorno

**Archivos:** `src/config.py`, `frontend/src/config/api.js`  
**Severidad:** üí° MEJORA

**Problema:**
- Configuraci√≥n mezclada con l√≥gica
- No hay archivos .env.example
- Dificulta deployment en diferentes entornos

**Recomendaci√≥n:**
```python
# src/config/settings.py
from pydantic import BaseSettings
from typing import List

class Settings(BaseSettings):
    # Database
    database_url: str
    database_pool_size: int = 5
    
    # Security
    allowed_origins: List[str] = ["http://localhost:3000"]
    secret_key: str
    
    # Application
    environment: str = "development"
    debug: bool = False
    log_level: str = "INFO"
    
    # Model
    model_dir: str = "./scripts/models/trained"
    upload_dir: str = "./uploads"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

```bash
# .env.example
DATABASE_URL=postgresql://user:password@localhost:5432/eduforge
ALLOWED_ORIGINS=http://localhost:3000,https://yourdomain.com
SECRET_KEY=your-secret-key-here
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG
```

---

### 17. Mejorar Estructura de Respuestas API

**M√∫ltiples Endpoints**  
**Severidad:** üí° MEJORA

**Problema:**
- Respuestas inconsistentes entre endpoints
- Falta de estructura est√°ndar
- Sin metadatos √∫tiles (timestamp, versi√≥n, etc.)

**Ejemplo actual:**
```python
return {"predictions": predictions}  # Endpoint 1
return JSONResponse(content={"resultados": resultados_dict})  # Endpoint 2
return {"success": True, "message": "..."}  # Endpoint 3
```

**Recomendaci√≥n:**
```python
# src/models/responses.py
from pydantic import BaseModel
from typing import Any, Optional, List
from datetime import datetime

class APIResponse(BaseModel):
    success: bool
    data: Optional[Any] = None
    message: Optional[str] = None
    errors: Optional[List[str]] = None
    timestamp: datetime = datetime.now()
    version: str = "1.0"

class PaginatedResponse(APIResponse):
    data: List[Any]
    page: int
    page_size: int
    total: int
    total_pages: int

# Uso en endpoints:
@app.get("/api/resultados-prediccion")
async def get_resultados_prediccion(page: int = 1, page_size: int = 50):
    try:
        # ... l√≥gica ...
        return PaginatedResponse(
            success=True,
            data=resultados_dict,
            page=page,
            page_size=page_size,
            total=total_count,
            total_pages=(total_count + page_size - 1) // page_size
        )
    except Exception as e:
        return APIResponse(
            success=False,
            message="Error al obtener resultados",
            errors=[str(e)]
        )
```

---

## üöÄ RENDIMIENTO

### 18. Cach√© de Predicciones del Modelo

**Archivo:** `frontend/src/utils/studentsCache.js`  
**Severidad:** üí° MEJORA

**Observaci√≥n:**
- El frontend implementa cach√© bien estructurado
- El backend NO implementa cach√©
- Cada request reprocesa desde la BD

**Recomendaci√≥n Backend:**
```python
# src/utils/cache.py
from functools import lru_cache
from datetime import datetime, timedelta
import hashlib

class PredictionCache:
    def __init__(self, ttl_seconds: int = 300):  # 5 minutos
        self.cache = {}
        self.ttl = timedelta(seconds=ttl_seconds)
    
    def _generate_key(self, data: str) -> str:
        """Genera key √∫nica basada en hash del contenido"""
        return hashlib.md5(data.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[List[Dict]]:
        """Obtiene del cach√© si no ha expirado"""
        if key in self.cache:
            data, timestamp = self.cache[key]
            if datetime.now() - timestamp < self.ttl:
                return data
            else:
                del self.cache[key]
        return None
    
    def set(self, key: str, value: List[Dict]):
        """Guarda en cach√© con timestamp"""
        self.cache[key] = (value, datetime.now())
    
    def clear(self):
        """Limpia todo el cach√©"""
        self.cache.clear()

# Instancia global
prediction_cache = PredictionCache()

# Uso en predictor.py
def predict_desertion(file_path: str) -> List[Dict]:
    # Generar key basado en hash del archivo
    with open(file_path, 'rb') as f:
        file_hash = hashlib.md5(f.read()).hexdigest()
    
    # Intentar obtener del cach√©
    cached_result = prediction_cache.get(file_hash)
    if cached_result:
        logger.info("‚úÖ Predicciones obtenidas del cach√©")
        return cached_result
    
    # Si no est√° en cach√©, procesar normalmente
    results = _process_predictions(file_path)
    
    # Guardar en cach√©
    prediction_cache.set(file_hash, results)
    
    return results
```

---

### 19. Optimizar Carga del Modelo ML

**Archivo:** `src/models/predictor.py` (l√≠neas 22-31)  
**Severidad:** üí° MEJORA

**Problema Actual:**
```python
# Carga del modelo al importar el m√≥dulo
try:
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    config = joblib.load(CONFIG_PATH)
```

**Problemas:**
1. Se carga en cada worker de uvicorn (desperdicio de memoria)
2. Carga s√≠ncrona bloquea el startup
3. Sin lazy loading

**Recomendaci√≥n:**
```python
# Singleton pattern para el modelo
class ModelManager:
    _instance = None
    _model = None
    _scaler = None
    _config = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def load_model(self):
        """Carga lazy del modelo"""
        if self._model is None:
            logger.info("Cargando modelo ML...")
            self._model = joblib.load(MODEL_PATH)
            self._scaler = joblib.load(SCALER_PATH)
            self._config = joblib.load(CONFIG_PATH)
            logger.info("‚úÖ Modelo cargado")
    
    @property
    def model(self):
        if self._model is None:
            self.load_model()
        return self._model
    
    @property
    def scaler(self):
        if self._scaler is None:
            self.load_model()
        return self._scaler
    
    @property
    def config(self):
        if self._config is None:
            self.load_model()
        return self._config

# Instancia global
model_manager = ModelManager()

# Uso
def predict_desertion(file_path: str):
    model = model_manager.model
    scaler = model_manager.scaler
    # ...
```

---

## üì± FRONTEND

### 20. Manejo de Cach√© en Frontend

**Archivo:** `frontend/src/utils/studentsCache.js`  
**Severidad:** ‚úÖ BUENA PR√ÅCTICA

**Observaci√≥n Positiva:**
El c√≥digo frontend tiene un buen sistema de cach√©:
- Invalidaci√≥n apropiada en cambios
- Eventos personalizados para sincronizaci√≥n
- Timeout de 5 minutos configurable
- Manejo de estado de carga

**Sugerencias menores:**
```javascript
// Agregar compresi√≥n para localStorage
class StudentsCache {
  saveToLocalStorage(key, data) {
    try {
      // Comprimir datos antes de guardar
      const compressed = LZString.compress(JSON.stringify(data));
      localStorage.setItem(key, compressed);
    } catch (error) {
      console.error('Error guardando en localStorage:', error);
      // Si falla, intentar limpiar cach√© antiguo
      this.invalidate();
    }
  }
  
  loadFromLocalStorage(key) {
    try {
      const compressed = localStorage.getItem(key);
      if (compressed) {
        return JSON.parse(LZString.decompress(compressed));
      }
    } catch (error) {
      console.error('Error cargando de localStorage:', error);
      return null;
    }
  }
}
```

---

## üìã DOCUMENTACI√ìN

### 21. Falta de Documentaci√≥n en Funciones Cr√≠ticas

**M√∫ltiples Archivos**  
**Severidad:** üí° MEJORA

**Problema:**
Muchas funciones carecen de docstrings adecuadas:

```python
# src/models/predictor.py
def prepare_features_real(df: pd.DataFrame) -> pd.DataFrame:
    """Prepara las caracter√≠sticas exactamente como el modelo entrenado las espera"""
    # ‚ö†Ô∏è Falta documentaci√≥n de:
    # - Qu√© columnas espera el DataFrame
    # - Qu√© transformaciones aplica
    # - Qu√© columnas retorna
    # - Ejemplos de uso
```

**Recomendaci√≥n:**
```python
def prepare_features_real(df: pd.DataFrame) -> pd.DataFrame:
    """
    Prepara caracter√≠sticas del DataFrame para el modelo de predicci√≥n.
    
    Esta funci√≥n transforma los datos crudos del CSV al formato que el modelo
    ML entrenado espera, aplicando las mismas transformaciones usadas durante
    el entrenamiento.
    
    Args:
        df: DataFrame con columnas requeridas:
            - nota_final (float): Nota del estudiante en escala 0-20
            - asistencia (float): Porcentaje de asistencia 0-100
            - inasistencia (float): Porcentaje de inasistencia 0-100
            - conducta (str): Categor√≠a de conducta ('positivo', 'neutral', 'agresivo')
    
    Returns:
        DataFrame con caracter√≠sticas transformadas:
            - nota_normalizada (float): Nota escalada a 0-1
            - conducta_encoded (int): Conducta codificada (0=positivo, 1=neutral, 2=agresivo)
            - asistencia_normalizada (float): Asistencia escalada a 0-1
            - inasistencia_normalizada (float): Inasistencia escalada a 0-1
            - nota_baja (int): Indicador binario si nota < 11
            - alta_inasistencia (int): Indicador binario si inasistencia > 30
            - conducta_problematica (int): Indicador binario si conducta agresiva
    
    Raises:
        ValueError: Si faltan columnas requeridas
        TypeError: Si los tipos de datos son incorrectos
    
    Example:
        >>> df = pd.DataFrame({
        ...     'nota_final': [15.0, 8.5],
        ...     'asistencia': [90.0, 60.0],
        ...     'inasistencia': [10.0, 40.0],
        ...     'conducta': ['positivo', 'neutral']
        ... })
        >>> features = prepare_features_real(df)
        >>> print(features.columns)
        ['nota_normalizada', 'conducta_encoded', 'asistencia_normalizada', ...]
    """
    # Implementaci√≥n...
```

---

## üîí SEGURIDAD ADICIONAL

### 22. Falta de Rate Limiting

**Archivo:** `src/main.py`  
**Severidad:** ‚ö†Ô∏è MEDIA

**Problema:**
- Sin l√≠mite de requests por IP/usuario
- Vulnerable a ataques DDoS
- Sin throttling en endpoints costosos

**Recomendaci√≥n:**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/predict")
@limiter.limit("10/minute")  # M√°ximo 10 predicciones por minuto
async def predict(request: Request, filename: str):
    # ...

@app.post("/upload")
@limiter.limit("5/minute")  # M√°ximo 5 uploads por minuto
async def upload_file(request: Request, file: UploadFile):
    # ...
```

---

### 23. Falta de Validaci√≥n de Tama√±o de Archivo

**Archivo:** `src/main.py`, `src/upload.py`  
**Severidad:** ‚ö†Ô∏è MEDIA

**Problema:**
```python
@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    # ‚ö†Ô∏è Sin validaci√≥n de tama√±o
    file_path = await save_uploaded_file(file)
```

**Riesgo:**
- Subida de archivos enormes puede agotar memoria/disco
- Ataque DoS subiendo archivos masivos

**Recomendaci√≥n:**
```python
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10 MB

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    # Validar extensi√≥n
    if not file.filename.endswith('.csv'):
        raise HTTPException(
            status_code=400,
            detail="Solo se permiten archivos CSV"
        )
    
    # Validar tama√±o
    file.file.seek(0, 2)  # Ir al final del archivo
    file_size = file.file.tell()  # Obtener posici√≥n = tama√±o
    file.file.seek(0)  # Volver al inicio
    
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"Archivo muy grande. M√°ximo: {MAX_FILE_SIZE / 1024 / 1024:.1f} MB"
        )
    
    # Continuar con la l√≥gica...
```

---

## üß™ TESTING

### 24. Estrategia de Testing Inexistente

**Severidad:** üî¥ CR√çTICA

**Problema:**
- No hay tests unitarios
- No hay tests de integraci√≥n
- No hay tests de API
- No hay cobertura de c√≥digo

**Recomendaci√≥n - Estructura de Tests:**

```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_predictor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ test_date_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ test_models.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py
‚îÇ   ‚îú‚îÄ‚îÄ test_database.py
‚îÇ   ‚îî‚îÄ‚îÄ test_upload_workflow.py
‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îî‚îÄ‚îÄ test_prediction_flow.py
‚îî‚îÄ‚îÄ conftest.py
```

**Ejemplos de Tests Prioritarios:**

```python
# tests/unit/test_predictor.py
import pytest
import pandas as pd
from src.models.predictor import (
    validate_input_data_real,
    prepare_features_real,
    classify_risk_level
)

def test_classify_risk_level():
    """Test de clasificaci√≥n de niveles de riesgo"""
    assert classify_risk_level(0.8) == "Alto"
    assert classify_risk_level(0.5) == "Medio"
    assert classify_risk_level(0.2) == "Bajo"

def test_validate_input_data_missing_columns():
    """Test de validaci√≥n con columnas faltantes"""
    df = pd.DataFrame({'col1': [1, 2]})
    assert validate_input_data_real(df) == False

def test_validate_input_data_valid():
    """Test de validaci√≥n con datos v√°lidos"""
    df = pd.DataFrame({
        'nota_final': [15.0],
        'asistencia': [90.0],
        'inasistencia': [10.0],
        'conducta': ['positivo']
    })
    assert validate_input_data_real(df) == True

def test_prepare_features_normalization():
    """Test de normalizaci√≥n de caracter√≠sticas"""
    df = pd.DataFrame({
        'nota_final': [20.0, 0.0],
        'asistencia': [100.0, 0.0],
        'inasistencia': [0.0, 100.0],
        'conducta': ['positivo', 'agresivo']
    })
    
    result = prepare_features_real(df)
    
    # Verificar normalizaci√≥n de nota
    assert result['nota_normalizada'].iloc[0] == 1.0
    assert result['nota_normalizada'].iloc[1] == 0.0
    
    # Verificar codificaci√≥n de conducta
    assert result['conducta_encoded'].iloc[0] == 0  # positivo
    assert result['conducta_encoded'].iloc[1] == 2  # agresivo
```

```python
# tests/integration/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient
from src.main import app
import tempfile
import pandas as pd

client = TestClient(app)

def test_upload_endpoint():
    """Test de endpoint /upload"""
    # Crear archivo CSV temporal
    df = pd.DataFrame({
        'estudiante_id': [1, 2],
        'nombre': ['Test 1', 'Test 2'],
        'nota_final': [15.0, 8.0],
        'asistencia': [90.0, 60.0],
        'inasistencia': [10.0, 40.0],
        'conducta': ['positivo', 'neutral']
    })
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        df.to_csv(f.name, index=False)
        
        with open(f.name, 'rb') as file:
            response = client.post(
                "/upload",
                files={"file": ("test.csv", file, "text/csv")}
            )
    
    assert response.status_code == 200
    data = response.json()
    assert data["success"] == True
    assert "filename" in data

def test_predict_endpoint():
    """Test de endpoint /predict"""
    # Primero subir un archivo
    # ... (usar test_upload_endpoint como helper)
    
    response = client.post("/predict", params={"filename": "test.csv"})
    
    assert response.status_code == 200
    data = response.json()
    assert "predictions" in data
    assert len(data["predictions"]) > 0

def test_estadisticas_endpoint():
    """Test de endpoint /api/estadisticas-generales"""
    response = client.get("/api/estadisticas-generales")
    
    assert response.status_code == 200
    data = response.json()
    assert "total_estudiantes" in data
    assert "porcentaje_riesgo" in data
```

**pytest.ini:**
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --cov=src
    --cov-report=html
    --cov-report=term
```

---

## üìä RESUMEN DE ISSUES POR PRIORIDAD

### üî¥ CR√çTICOS (Requieren atenci√≥n inmediata)

1. **Credenciales Hardcodeadas** - config.py
2. **Ausencia de Tests** - tests/
3. **Falta de Validaci√≥n en APIs** - main.py

### ‚ö†Ô∏è ALTOS (Deben resolverse pronto)

4. **Gesti√≥n de Sesiones de BD** - M√∫ltiples archivos
5. **Variables Globales Thread-Unsafe** - risk_service.py
6. **Inconsistencia de Campos** - main.py, predictor.py

### üí° MEJORAS (Cuando haya tiempo)

7-11. Logging, CORS, Feature Engineering, Generaci√≥n de Nombres, Fechas
12-15. Refactoring, Optimizaci√≥n, Validaci√≥n
16-19. Arquitectura, Respuestas API, Cach√©, Carga de Modelo
20-23. Frontend, Documentaci√≥n, Rate Limiting, Tama√±o de Archivos

---

## ‚úÖ ASPECTOS POSITIVOS DEL C√ìDIGO

1. **Buena estructura de proyecto** - Separaci√≥n clara de concerns (models, services, api)
2. **Uso de FastAPI** - Framework moderno y bien implementado
3. **Logging estructurado** - En la mayor√≠a de lugares (aunque mejorable)
4. **Manejo de ML profesional** - Uso correcto de scikit-learn y joblib
5. **Frontend con cach√©** - Implementaci√≥n s√≥lida de cach√© en React
6. **Documentaci√≥n README** - README.md bien estructurado
7. **CORS configurado** - Aunque permisivo, est√° presente
8. **Migraciones autom√°ticas** - Sistema de migraciones implementado
9. **Separaci√≥n de concerns** - Services, models, api routes bien organizados

---

## üéØ PLAN DE ACCI√ìN RECOMENDADO

### Fase 1: Seguridad (1-2 semanas)
- [ ] Remover credenciales hardcodeadas
- [ ] Implementar validaci√≥n de entrada en todos los endpoints
- [ ] Agregar rate limiting
- [ ] Validar tama√±os de archivo
- [ ] Auditor√≠a de seguridad completa

### Fase 2: Calidad (2-3 semanas)
- [ ] Implementar suite de tests unitarios
- [ ] Implementar tests de integraci√≥n
- [ ] Configurar CI/CD con tests autom√°ticos
- [ ] Alcanzar 70%+ cobertura de c√≥digo
- [ ] Agregar linting autom√°tico (flake8, black, mypy)

### Fase 3: Refactoring (2-3 semanas)
- [ ] Unificar nomenclatura de campos
- [ ] Refactorizar endpoints monol√≠ticos
- [ ] Implementar context managers para BD
- [ ] Extraer feature engineering com√∫n
- [ ] Mejorar manejo de excepciones

### Fase 4: Optimizaci√≥n (1-2 semanas)
- [ ] Implementar cach√© en backend
- [ ] Optimizar queries de BD con √≠ndices
- [ ] Implementar paginaci√≥n
- [ ] Lazy loading del modelo ML
- [ ] Profiling de performance

### Fase 5: Documentaci√≥n (1 semana)
- [ ] Completar docstrings en todas las funciones
- [ ] Generar documentaci√≥n API con Swagger
- [ ] Crear gu√≠as de deployment
- [ ] Documentar arquitectura
- [ ] Crear ejemplos de uso

---

## üìö RECURSOS RECOMENDADOS

### Librer√≠as √ötiles
- **pytest** - Framework de testing
- **pytest-cov** - Cobertura de c√≥digo
- **black** - Formateo autom√°tico de c√≥digo
- **flake8** - Linting de Python
- **mypy** - Type checking
- **slowapi** - Rate limiting para FastAPI
- **python-dotenv** - Manejo de variables de entorno
- **pydantic** - Validaci√≥n de datos
- **alembic** - Migraciones de BD m√°s robustas
- **redis** - Cach√© distribuido

### Gu√≠as y Best Practices
- [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices)
- [SQLAlchemy Best Practices](https://docs.sqlalchemy.org/en/14/orm/session_basics.html)
- [Python Testing Best Practices](https://docs.pytest.org/en/stable/goodpractices.html)
- [Security Best Practices](https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html)

---

## üèÅ CONCLUSI√ìN

El proyecto **EduForge** tiene una base s√≥lida y est√° bien estructurado. Sin embargo, requiere atenci√≥n en aspectos cr√≠ticos de **seguridad** y **testing** antes de considerarlo production-ready.

### Puntos Fuertes
- Arquitectura limpia y organizada
- Uso apropiado de tecnolog√≠as modernas
- Funcionalidad core bien implementada

### √Åreas de Mejora Prioritarias
- Seguridad (credenciales, validaci√≥n)
- Testing (cobertura, automatizaci√≥n)
- Mantenibilidad (documentaci√≥n, refactoring)

### Recomendaci√≥n Final
**NO** desplegar a producci√≥n hasta resolver los issues cr√≠ticos (üî¥).  
Una vez resueltos, el sistema estar√° listo para un ambiente productivo con usuarios reales.

---

**Revisi√≥n Completa - EduForge System**  
*Documento generado autom√°ticamente por GitHub Copilot Agent*
